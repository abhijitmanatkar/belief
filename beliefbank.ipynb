{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "from enum import Enum\n",
    "from typing import List, Dict\n",
    "import copy\n",
    "import json\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"allenai/unifiedqa-v2-t5-small-1251000\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./constraints_v2.json', 'r') as f:\n",
    "    constraint_data = json.load(f)\n",
    "\n",
    "with open('./silver_facts.json', 'r') as f:\n",
    "    fact_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(model, tokenizer, raw_input, output_options):\n",
    "    output_scores = []\n",
    "    with torch.no_grad():\n",
    "        input_ids = tokenizer.encode(raw_input, return_tensors=\"pt\")\n",
    "        for option in output_options:\n",
    "            output_ids = tokenizer.encode(option, return_tensors=\"pt\")\n",
    "            res = model(input_ids, labels=output_ids, return_dict=True)\n",
    "            score = torch.exp(-res.loss)\n",
    "            output_scores.append((option, score.numpy()))\n",
    "    return output_scores\n",
    "\n",
    "def get_raw_input(question, options):\n",
    "    raw_input = question + ' \\n'\n",
    "    for option_num, option in zip(list(string.ascii_uppercase), options):\n",
    "        raw_input += f' ({option_num}) {option}'\n",
    "    return raw_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackType(Enum):\n",
    "    RELEVANT = 0\n",
    "    ON_TOPIC_RANDOM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_PRECISION = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predicate():\n",
    "    \"\"\"A predicate is a generalized sentence which can be substituted with entities.\n",
    "    Example 'IsA,dog' is a predicate in which if we substitute the entity 'poodle',\n",
    "    we get the sentence 'A poodle is a dog'.\n",
    "\n",
    "    Args:\n",
    "        str_rep: String representation of predicate, ex 'IsA,mammal', 'HasA,tail'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, str_rep):\n",
    "        self.str_rep = str_rep\n",
    "        self.relation, self.object = str_rep.split(\",\")\n",
    "        if self.relation not in ['CapableOf', 'HasA', 'HasPart', 'HasProperty', 'IsA', 'MadeOf']:\n",
    "            raise Exception(f\"{self.relation} is an unsupported relation\")\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.relation},{self.object}\"\n",
    "\n",
    "    def substitute(self, subject):\n",
    "        \"\"\"Returns sentence, i.e. 'subject,relation,object' on substituting subject in\n",
    "        the predicate.\n",
    "        \"\"\"\n",
    "        return f\"{subject},{self.relation},{self.object}\"\n",
    "\n",
    "class Proposition():\n",
    "    \"\"\"A proposition, Can be a belief when present in a belief bank\n",
    "\n",
    "    Attributes:\n",
    "        subject: The subject of the proposition\n",
    "        predicate: The general predicate of the proposition in which the subject is substituted.\n",
    "        boolean: The Truth value of the sentence\n",
    "        weight: Optional attribute indicating the weight of the proposition. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        subject: str,\n",
    "        predicate: Predicate,\n",
    "        boolean: bool = True,\n",
    "        weight: float = -99999,\n",
    "    ):\n",
    "        self.subject = subject\n",
    "        self.predicate = predicate\n",
    "        self.boolean = boolean\n",
    "        self.weight = int(round(weight * (10**WEIGHT_PRECISION), WEIGHT_PRECISION))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"({self.sentence}, {self.boolean}, {self.weight / (10**WEIGHT_PRECISION)})\"\n",
    "\n",
    "    @property\n",
    "    def sentence(self):\n",
    "        return self.predicate.substitute(self.subject)\n",
    "\n",
    "    def get_nl_sentence(self):\n",
    "        \"\"\"Returns natural language sentence expressing the proposition\"\"\"\n",
    "        if self.predicate.relation == 'IsA':\n",
    "            return f\"{self.subject} is a {self.predicate.object}.\"\n",
    "        if self.predicate.relation == \"MadeOf\":\n",
    "            return f\"{self.subject} is made of {self.predicate.object}.\"\n",
    "        if self.predicate.relation == \"CapableOf\":\n",
    "            return f\"{self.subject} is capable of {self.predicate.object}.\"\n",
    "        if self.predicate.relation == \"HasA\":\n",
    "            return f\"{self.subject} has a {self.predicate.object}.\"\n",
    "        if self.predicate.relation == \"HasPart\":\n",
    "            return f\"A {self.predicate.object} is part of a {self.subject}.\"\n",
    "        if self.predicate.relation == \"HasProperty\":\n",
    "            return f\"{self.subject} has the property of being {self.object}.\"\n",
    "\n",
    "    def get_nl_question(self):\n",
    "        \"\"\"Returns natural language sentence asking the proposition\"\"\"\n",
    "        if self.predicate.relation == 'IsA':\n",
    "            return f\"Is a {self.subject} a {self.predicate.object}?\"\n",
    "        if self.predicate.relation == \"MadeOf\":\n",
    "            return f\"Is a {self.subject} made of {self.predicate.object}?\"\n",
    "        if self.predicate.relation == \"CapableOf\":\n",
    "            return f\"Is a {self.subject} capable of {self.predicate.object}?\"\n",
    "        if self.predicate.relation == \"HasA\":\n",
    "            return f\"Does a {self.subject} have a {self.predicate.object}?\"\n",
    "        if self.predicate.relation == \"HasPart\":\n",
    "            return f\"Is a {self.predicate.object} part of a {self.subject}?\"\n",
    "        if self.predicate.relation == \"HasProperty\":\n",
    "            return f\"Does {self.subject} have the property of being {self.object}?\"\n",
    "\n",
    "class Constraint():\n",
    "    \"\"\"Class for constraint\n",
    "    \n",
    "    Attributes:\n",
    "        src_predicate: The source predicate\n",
    "        dest_predicate: The destination predicate\n",
    "        weight: Penalty for violation of constraint\n",
    "        implication: Indicates the type of implication in the constraint (T->F, T->T, F->T, F->F)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_predicate: Predicate,\n",
    "        dest_predicate: Predicate,\n",
    "        weight: float,\n",
    "        implication: str\n",
    "    ):\n",
    "        self.src_predicate = src_predicate\n",
    "        self.dest_predicate = dest_predicate\n",
    "        self.weight = int(round(weight * (10**WEIGHT_PRECISION), WEIGHT_PRECISION))\n",
    "        self.implication = implication\n",
    "\n",
    "    @classmethod\n",
    "    def from_raw(cls, raw_link):\n",
    "        if raw_link['direction'] == 'forward':\n",
    "            src_predicate = raw_link['source']\n",
    "            dest_predicate = raw_link['target']\n",
    "        elif raw_link['direction'] == 'back':\n",
    "            src_predicate = raw_link['target']\n",
    "            dest_predicate = raw_link['source']\n",
    "\n",
    "        return Constraint(\n",
    "            src_predicate=Predicate(src_predicate),\n",
    "            dest_predicate=Predicate(dest_predicate),\n",
    "            weight=raw_link['score'],\n",
    "            implication=raw_link['weight']\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        s, d = self.implication.split('_')\n",
    "        return f\"Constraint(<{'¬' if s == 'no' else ''}{self.src_predicate.str_rep} ⟶ {'¬' if d == 'no' else ''}{self.dest_predicate.str_rep}>, {self.weight / {10**WEIGHT_PRECISION}})\"\n",
    "\n",
    "\n",
    "class LMBB():\n",
    "    \"\"\"Langauge Model + Belief Bank\"\"\"\n",
    "\n",
    "    def __init__(self, model, tokenizer, raw_constraints):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        self.constraints = [Constraint.from_raw(c) for c in raw_constraints]\n",
    "        self.links: Dict[str, List[Constraint]] = defaultdict(list)\n",
    "        for constraint in self.constraints:\n",
    "            self.links[constraint.src_predicate.str_rep].append(constraint)\n",
    "        \n",
    "        # Dictionary where the key is 'subject,relation,predicate' and value is a proposition\n",
    "        self.beliefs = dict()\n",
    "\n",
    "        # Feedback config\n",
    "        self.num_random_on_topic_beliefs = 3\n",
    "        self.num_relevant_beliefs = 3\n",
    "\n",
    "    def get_beliefs_by_subject(self, subject):\n",
    "        subject_beliefs = [self.beliefs[key] for key in self.beliefs.keys() if key.split(\",\")[0] == subject]\n",
    "        return subject_beliefs\n",
    "\n",
    "    def add_belief(\n",
    "        self, \n",
    "        proposition: Proposition,\n",
    "        constraint_solving: bool = True,\n",
    "        with_feedback: bool = True,\n",
    "        feedback_type: FeedbackType = FeedbackType.RELEVANT\n",
    "    ):\n",
    "        \"\"\"Adds a single proposition to the systems existing set of beliefs\n",
    "        Args:\n",
    "            proposition: New proposition to add\n",
    "            constraint_solving: Whether to use constraint solving or not\n",
    "            with_feedback: Whether to use feedback or not\n",
    "            feedback_type: RELEVANT / ON_TOPIC_RANDOM\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get proposition after passing through language model with/without feedback\n",
    "        proposition = self.query(proposition, with_feedback, feedback_type)\n",
    "\n",
    "        # Optional constraint solving\n",
    "        if constraint_solving:\n",
    "            beliefs = list(self.beliefs.values())\n",
    "            beliefs.append(proposition)\n",
    "            new_beliefs = self.maxSat(beliefs)\n",
    "        else:\n",
    "            new_beliefs = [proposition]\n",
    "        self.set_beliefs(new_beliefs)\n",
    "\n",
    "    def add_belief_set(\n",
    "        self, \n",
    "        propositions: List[Proposition],\n",
    "        constraint_solving: bool = True,\n",
    "        with_feedback: bool = True,\n",
    "        feedback_type: FeedbackType = FeedbackType.RELEVANT\n",
    "    ):\n",
    "        \"\"\"Adds a set of proposition to the systems existing set of beliefs\n",
    "        Args:\n",
    "            propositions: List of new propositions to add\n",
    "            constraint_solving: Whether to use constraint solving or not\n",
    "            with_feedback: Whether to use feedback or not\n",
    "            feedback_type: RELEVANT / ON_TOPIC_RANDOM\n",
    "        \"\"\"\n",
    "        propositions = [self.query(proposition, with_feedback, feedback_type) for proposition in propositions]\n",
    "        \n",
    "        # Optional constraint solving\n",
    "        if constraint_solving:\n",
    "            beliefs = list(self.beliefs.values())\n",
    "            beliefs += propositions\n",
    "            new_beliefs = self.maxSat(beliefs)\n",
    "        else:\n",
    "            new_beliefs = propositions\n",
    "        self.set_beliefs(new_beliefs)\n",
    "\n",
    "    def set_beliefs(self, new_beliefs):\n",
    "        for belief in new_beliefs:\n",
    "            self.beliefs[belief.sentence] = belief\n",
    "\n",
    "    def query(self, proposition: Proposition, with_feedback=True, feedback_type=FeedbackType.RELEVANT):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            proposition: the query to the LMBB system\n",
    "            with_feedback: Whether to use context from existing beliefs or not\n",
    "            feedback_type: RELEVANT / ON_TOPIC_RANDOM \n",
    "\n",
    "        Returns:\n",
    "            proposition: The updated proposition with truth value and weight\n",
    "        \"\"\"\n",
    "        \n",
    "        feedback_beliefs = []\n",
    "        if with_feedback:\n",
    "            feedback_beliefs = self.feedback(proposition, feedback_type)\n",
    "        feedback_string = \" \".join([belief.get_nl_sentence() for belief in feedback_beliefs])\n",
    "        question = feedback_string + ' ' + proposition.get_nl_question()\n",
    "\n",
    "        # TODO: Grammar model to refine the question\n",
    "        \n",
    "        options = ['yes', 'no']\n",
    "        \n",
    "        raw_input = get_raw_input(question, options)\n",
    "        logging.debug(raw_input)\n",
    "        scores = get_scores(self.model, self.tokenizer, raw_input, options)\n",
    "        logging.debug(scores)\n",
    "        answer = max(scores, key=lambda x: x[1])\n",
    "\n",
    "        return Proposition(\n",
    "            subject=proposition.subject,\n",
    "            predicate=proposition.predicate,\n",
    "            boolean=True if answer[0] == 'yes' else False,\n",
    "            weight=answer[1]\n",
    "        )\n",
    "    \n",
    "    def maxSat(self, beliefs: List[Proposition]):\n",
    "        \"\"\"Run MaxSAT solver considering 'beliefs' and constraints\n",
    "        \n",
    "        Args:\n",
    "            beliefs: List of propositions\n",
    "        \n",
    "        Returns:\n",
    "            new_beliefs: List of modified beliefs to ensure maximum satisfiability\n",
    "        \"\"\"\n",
    "        optim = Optimize()\n",
    "\n",
    "        belief_bools = {}\n",
    "        belief_props = {}\n",
    "        \n",
    "        subjects = set()\n",
    "\n",
    "        for prop in beliefs:\n",
    "            subjects.add(prop.subject)\n",
    "            sentence = prop.sentence\n",
    "            if sentence not in belief_bools:\n",
    "                belief_bools[sentence] = Bool(sentence)\n",
    "                belief_props[sentence] = prop\n",
    "            if prop.boolean == True:\n",
    "                optim.add_soft(belief_bools[sentence], prop.weight)\n",
    "            else:\n",
    "                optim.add_soft(Not(belief_bools[sentence]), prop.weight)\n",
    "\n",
    "        for constraint in self.constraints:\n",
    "            for subject in subjects:\n",
    "                src_sent = constraint.src_predicate.substitute(subject)\n",
    "                dest_sent = constraint.dest_predicate.substitute(subject)\n",
    "\n",
    "                src_bool = belief_bools[src_sent] if src_sent in belief_bools else Bool(src_sent)\n",
    "                dest_bool = belief_bools[dest_sent] if dest_sent in belief_bools else Bool(dest_sent)\n",
    "\n",
    "                if constraint.implication == \"yes_yes\":\n",
    "                    optim.add_soft(Implies(src_bool, dest_bool), constraint.weight)\n",
    "                elif constraint.implication == \"yes_no\":\n",
    "                    optim.add_soft(Implies(src_bool, Not(dest_bool)), constraint.weight)\n",
    "                elif constraint.implication == \"no_yes\":\n",
    "                    optim.add_soft(Implies(Not(src_bool), src_bool), constraint.weight)\n",
    "                elif constraint.implication == \"no_no\":\n",
    "                    optim.add_soft(Implies(Not(src_bool), Not(dest_bool)), constraint.weight)\n",
    "\n",
    "        optim.check()\n",
    "        mod = optim.model()\n",
    "\n",
    "        new_beliefs = copy.deepcopy(beliefs)\n",
    "        for prop in new_beliefs:\n",
    "            sentence = prop.sentence\n",
    "            prop.boolean = mod.evaluate(belief_bools[sentence])\n",
    "        \n",
    "        return new_beliefs\n",
    "\n",
    "    def feedback(self, proposition: Proposition, feedback_type=FeedbackType.RELEVANT):\n",
    "        \"\"\"Returns feedback beliefs corresponding to the given proposition using one of multiple strategies.\"\"\"\n",
    "        \n",
    "        if feedback_type == FeedbackType.ON_TOPIC_RANDOM:\n",
    "            on_topic_beliefs = self.get_beliefs_by_subject(proposition.subject)\n",
    "            return list(np.random.choice(on_topic_beliefs, min(self.num_random_on_topic_beliefs, len(on_topic_beliefs)), replace=False))\n",
    "\n",
    "        elif feedback_type == FeedbackType.RELEVANT:\n",
    "            # Sorting according to descending order\n",
    "            clashing_beliefs = sorted(self.get_clashing_beliefs(proposition), key=lambda prop: -prop.weight)\n",
    "            if len(clashing_beliefs) < self.num_relevant_beliefs:\n",
    "                clashing_beliefs += list(self.beliefs.values())[:self.num_relevant_beliefs - len(clashing_beliefs)]\n",
    "            return clashing_beliefs[:self.num_relevant_beliefs]\n",
    "            \n",
    "\n",
    "    def get_clashing_beliefs(self, proposition: Proposition):\n",
    "        \"\"\"Returns a list of beliefs present in the model that are inconsistent with the given proposition\"\"\"\n",
    "        \n",
    "        subject = proposition.subject\n",
    "        clashing_beliefs = []\n",
    "\n",
    "        visited_nodes = set()\n",
    "        def dfs(predicate: Predicate, expected_truth: bool):\n",
    "            visited_nodes.add(predicate.str_rep)\n",
    "            sentence = predicate.substitute(subject)\n",
    "            if self.beliefs[sentence].boolean != expected_truth:\n",
    "                clashing_beliefs.append(self.beliefs[sentence])\n",
    "            for constraint in self.links[predicate.str_rep]:\n",
    "                if not constraint.dest_predicate.str_rep in visited_nodes:\n",
    "                    if constraint.implication == \"yes_yes\" and expected_truth == True:\n",
    "                        dfs(constraint.dest_predicate, True)\n",
    "                    elif constraint.implication == \"yes_no\" and expected_truth == True:\n",
    "                        dfs(constraint.dest_predicate, False)\n",
    "                    elif constraint.implication == \"no_yes\" and expected_truth == False:\n",
    "                        dfs(constraint.dest_predicate, True)\n",
    "                    elif constraint.implication == \"no_no\" and expected_truth == False:\n",
    "                        dfs(constraint.dest_predicate, False)\n",
    "\n",
    "        return clashing_beliefs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = []\n",
    "for subject in fact_data.keys():\n",
    "    for predicate_str_rep in fact_data[subject]:\n",
    "        prop = Proposition(\n",
    "            subject=subject,\n",
    "            predicate=Predicate(predicate_str_rep)\n",
    "        )\n",
    "        facts.append(prop)\n",
    "random.shuffle(facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbb = LMBB(model=model, tokenizer=tokenizer, raw_constraints=constraint_data['links'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_facts = [fact for fact in facts if fact.boolean == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root: Is a starling a terrestrial organism? \n",
      " (A) yes (B) no\n",
      "DEBUG:root:[('yes', array(0.2710582, dtype=float32)), ('no', array(0.9625627, dtype=float32))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(starling,IsA,terrestrial organism, False, 0.962)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = random.randint(0, len(true_facts))\n",
    "print(idx)\n",
    "lmbb.query(true_facts[idx], with_feedback=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('advnlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22bb8309d38f1e65544d46771276df01ff94c6adf407f8023f86ac86fc1d49c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
