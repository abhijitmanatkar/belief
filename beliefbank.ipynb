{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "from enum import Enum\n",
    "from typing import List, Dict\n",
    "import copy\n",
    "import json\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /allenai/unifiedqa-v2-t5-small-1251000/resolve/main/spiece.model HTTP/1.1\" 302 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /allenai/unifiedqa-v2-t5-small-1251000/resolve/main/added_tokens.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /allenai/unifiedqa-v2-t5-small-1251000/resolve/main/special_tokens_map.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /allenai/unifiedqa-v2-t5-small-1251000/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /allenai/unifiedqa-v2-t5-small-1251000/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /allenai/unifiedqa-v2-t5-small-1251000/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n"
     ]
    }
   ],
   "source": [
    "model_name = \"allenai/unifiedqa-v2-t5-small-1251000\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/constraints_v2.json', 'r') as f:\n",
    "    constraint_data = json.load(f)\n",
    "\n",
    "with open('./data/silver_facts.json', 'r') as f:\n",
    "    fact_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(model, tokenizer, raw_input, output_options):\n",
    "    output_scores = []\n",
    "    with torch.no_grad():\n",
    "        input_ids = tokenizer.encode(raw_input, return_tensors=\"pt\")\n",
    "        for option in output_options:\n",
    "            output_ids = tokenizer.encode(option, return_tensors=\"pt\")\n",
    "            res = model(input_ids, labels=output_ids, return_dict=True)\n",
    "            score = torch.exp(-res.loss)\n",
    "            output_scores.append((option, score.numpy()))\n",
    "    return output_scores\n",
    "\n",
    "def get_raw_input(question, options):\n",
    "    raw_input = question + ' \\n'\n",
    "    for option_num, option in zip(list(string.ascii_uppercase), options):\n",
    "        raw_input += f' ({option_num}) {option}'\n",
    "    return raw_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackType(Enum):\n",
    "    RELEVANT = 0\n",
    "    ON_TOPIC_RANDOM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_PRECISION = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predicate():\n",
    "    \"\"\"A predicate is a generalized sentence which can be substituted with entities.\n",
    "    Example 'IsA,dog' is a predicate in which if we substitute the entity 'poodle',\n",
    "    we get the sentence 'A poodle is a dog'.\n",
    "\n",
    "    Args:\n",
    "        str_rep: String representation of predicate, ex 'IsA,mammal', 'HasA,tail'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, str_rep):\n",
    "        self.str_rep = str_rep\n",
    "        self.relation, self.object = str_rep.split(\",\")\n",
    "        if self.relation not in ['CapableOf', 'HasA', 'HasPart', 'HasProperty', 'IsA', 'MadeOf']:\n",
    "            raise Exception(f\"{self.relation} is an unsupported relation\")\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.relation},{self.object}\"\n",
    "\n",
    "    def substitute(self, subject):\n",
    "        \"\"\"Returns sentence, i.e. 'subject,relation,object' on substituting subject in\n",
    "        the predicate.\n",
    "        \"\"\"\n",
    "        return f\"{subject},{self.relation},{self.object}\"\n",
    "\n",
    "class Proposition():\n",
    "    \"\"\"A proposition, Can be a belief when present in a belief bank\n",
    "\n",
    "    Attributes:\n",
    "        subject: The subject of the proposition\n",
    "        predicate: The general predicate of the proposition in which the subject is substituted.\n",
    "        boolean: The Truth value of the sentence\n",
    "        weight: Optional attribute indicating the weight of the proposition. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        subject: str,\n",
    "        predicate: Predicate,\n",
    "        boolean: bool = True,\n",
    "        weight: float = -99999,\n",
    "    ):\n",
    "        self.subject = subject\n",
    "        self.predicate = predicate\n",
    "        self.boolean = boolean\n",
    "        self.weight = int(round(weight * (10**WEIGHT_PRECISION), WEIGHT_PRECISION))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"({self.sentence}, {self.boolean}, {self.weight / (10**WEIGHT_PRECISION)})\"\n",
    "\n",
    "    @property\n",
    "    def sentence(self):\n",
    "        return self.predicate.substitute(self.subject)\n",
    "\n",
    "    def get_nl_sentence(self):\n",
    "        \"\"\"Returns natural language sentence expressing the proposition\"\"\"\n",
    "        if self.predicate.relation == 'IsA':\n",
    "            return f\"{self.subject} is a {self.predicate.object}.\"\n",
    "        if self.predicate.relation == \"MadeOf\":\n",
    "            return f\"{self.subject} is made of {self.predicate.object}.\"\n",
    "        if self.predicate.relation == \"CapableOf\":\n",
    "            return f\"{self.subject} is capable of {self.predicate.object}.\"\n",
    "        if self.predicate.relation == \"HasA\":\n",
    "            return f\"{self.subject} has a {self.predicate.object}.\"\n",
    "        if self.predicate.relation == \"HasPart\":\n",
    "            return f\"A {self.predicate.object} is part of a {self.subject}.\"\n",
    "        if self.predicate.relation == \"HasProperty\":\n",
    "            return f\"{self.subject} has the property of being {self.predicate.object}.\"\n",
    "\n",
    "    def get_nl_question(self):\n",
    "        \"\"\"Returns natural language sentence asking the proposition\"\"\"\n",
    "        if self.predicate.relation == 'IsA':\n",
    "            return f\"Is a {self.subject} a {self.predicate.object}?\"\n",
    "        if self.predicate.relation == \"MadeOf\":\n",
    "            return f\"Is a {self.subject} made of {self.predicate.object}?\"\n",
    "        if self.predicate.relation == \"CapableOf\":\n",
    "            return f\"Is a {self.subject} capable of {self.predicate.object}?\"\n",
    "        if self.predicate.relation == \"HasA\":\n",
    "            return f\"Does a {self.subject} have a {self.predicate.object}?\"\n",
    "        if self.predicate.relation == \"HasPart\":\n",
    "            return f\"Is a {self.predicate.object} part of a {self.subject}?\"\n",
    "        if self.predicate.relation == \"HasProperty\":\n",
    "            return f\"Does {self.subject} have the property of being {self.predicate.object}?\"\n",
    "\n",
    "class Constraint():\n",
    "    \"\"\"Class for constraint\n",
    "    \n",
    "    Attributes:\n",
    "        src_predicate: The source predicate\n",
    "        dest_predicate: The destination predicate\n",
    "        weight: Penalty for violation of constraint\n",
    "        implication: Indicates the type of implication in the constraint (T->F, T->T, F->T, F->F)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_predicate: Predicate,\n",
    "        dest_predicate: Predicate,\n",
    "        weight: float,\n",
    "        implication: str\n",
    "    ):\n",
    "        self.src_predicate = src_predicate\n",
    "        self.dest_predicate = dest_predicate\n",
    "        self.weight = int(round(weight * (10**WEIGHT_PRECISION), WEIGHT_PRECISION))\n",
    "        self.implication = implication\n",
    "\n",
    "    @classmethod\n",
    "    def from_raw(cls, raw_link):\n",
    "        if raw_link['direction'] == 'forward':\n",
    "            src_predicate = raw_link['source']\n",
    "            dest_predicate = raw_link['target']\n",
    "        elif raw_link['direction'] == 'back':\n",
    "            src_predicate = raw_link['target']\n",
    "            dest_predicate = raw_link['source']\n",
    "\n",
    "        return Constraint(\n",
    "            src_predicate=Predicate(src_predicate),\n",
    "            dest_predicate=Predicate(dest_predicate),\n",
    "            weight=raw_link['score'],\n",
    "            implication=raw_link['weight']\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        s, d = self.implication.split('_')\n",
    "        return f\"Constraint(<{'¬' if s == 'no' else ''}{self.src_predicate.str_rep} ⟶ {'¬' if d == 'no' else ''}{self.dest_predicate.str_rep}>, {self.weight / {10**WEIGHT_PRECISION}})\"\n",
    "\n",
    "\n",
    "class LMBB():\n",
    "    \"\"\"Langauge Model + Belief Bank\"\"\"\n",
    "\n",
    "    def __init__(self, model, tokenizer, raw_constraints):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        self.constraints = [Constraint.from_raw(c) for c in raw_constraints]\n",
    "        self.links: Dict[str, List[Constraint]] = defaultdict(list)\n",
    "        for constraint in self.constraints:\n",
    "            self.links[constraint.src_predicate.str_rep].append(constraint)\n",
    "        \n",
    "        # Dictionary where the key is 'subject,relation,predicate' and value is a proposition\n",
    "        self.beliefs = dict()\n",
    "\n",
    "        # Feedback config\n",
    "        self.num_random_on_topic_beliefs = 3\n",
    "        self.num_relevant_beliefs = 3\n",
    "\n",
    "    def get_beliefs_by_subject(self, subject):\n",
    "        subject_beliefs = [self.beliefs[key] for key in self.beliefs.keys() if key.split(\",\")[0] == subject]\n",
    "        return subject_beliefs\n",
    "\n",
    "    def add_belief(\n",
    "        self, \n",
    "        proposition: Proposition,\n",
    "        constraint_solving: bool = True,\n",
    "        with_feedback: bool = True,\n",
    "        feedback_type: FeedbackType = FeedbackType.RELEVANT\n",
    "    ):\n",
    "        \"\"\"Adds a single proposition to the systems existing set of beliefs\n",
    "        Args:\n",
    "            proposition: New proposition to add\n",
    "            constraint_solving: Whether to use constraint solving or not\n",
    "            with_feedback: Whether to use feedback or not\n",
    "            feedback_type: RELEVANT / ON_TOPIC_RANDOM\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get proposition after passing through language model with/without feedback\n",
    "        proposition = self.query(proposition, with_feedback, feedback_type)\n",
    "\n",
    "        # Optional constraint solving\n",
    "        if constraint_solving:\n",
    "            beliefs = list(self.beliefs.values())\n",
    "            beliefs.append(proposition)\n",
    "            new_beliefs = self.maxSat(beliefs)\n",
    "        else:\n",
    "            new_beliefs = [proposition]\n",
    "        self.set_beliefs(new_beliefs)\n",
    "\n",
    "    def add_belief_set(\n",
    "        self, \n",
    "        propositions: List[Proposition],\n",
    "        constraint_solving: bool = True,\n",
    "        with_feedback: bool = True,\n",
    "        feedback_type: FeedbackType = FeedbackType.RELEVANT\n",
    "    ):\n",
    "        \"\"\"Adds a set of proposition to the systems existing set of beliefs\n",
    "        Args:\n",
    "            propositions: List of new propositions to add\n",
    "            constraint_solving: Whether to use constraint solving or not\n",
    "            with_feedback: Whether to use feedback or not\n",
    "            feedback_type: RELEVANT / ON_TOPIC_RANDOM\n",
    "        \"\"\"\n",
    "        propositions = [self.query(proposition, with_feedback, feedback_type) for proposition in propositions]\n",
    "        \n",
    "        # Optional constraint solving\n",
    "        if constraint_solving:\n",
    "            beliefs = list(self.beliefs.values())\n",
    "            beliefs += propositions\n",
    "            new_beliefs = self.maxSat(beliefs)\n",
    "        else:\n",
    "            new_beliefs = propositions\n",
    "        self.set_beliefs(new_beliefs)\n",
    "\n",
    "    def set_beliefs(self, new_beliefs):\n",
    "        for belief in new_beliefs:\n",
    "            self.beliefs[belief.sentence] = belief\n",
    "\n",
    "    def query(self, proposition: Proposition, with_feedback=True, feedback_type=FeedbackType.RELEVANT):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            proposition: the query to the LMBB system\n",
    "            with_feedback: Whether to use context from existing beliefs or not\n",
    "            feedback_type: RELEVANT / ON_TOPIC_RANDOM \n",
    "\n",
    "        Returns:\n",
    "            proposition: The updated proposition with truth value and weight\n",
    "        \"\"\"\n",
    "        \n",
    "        feedback_beliefs = []\n",
    "        if with_feedback:\n",
    "            feedback_beliefs = self.feedback(proposition, feedback_type)\n",
    "        feedback_string = \" \".join([belief.get_nl_sentence() for belief in feedback_beliefs])\n",
    "        question = feedback_string + ' ' + proposition.get_nl_question()\n",
    "\n",
    "        # TODO: Grammar model to refine the question\n",
    "        \n",
    "        options = ['yes', 'no']\n",
    "        \n",
    "        raw_input = get_raw_input(question, options)\n",
    "        scores = get_scores(self.model, self.tokenizer, raw_input, options)\n",
    "        answer = max(scores, key=lambda x: x[1])\n",
    "\n",
    "        return Proposition(\n",
    "            subject=proposition.subject,\n",
    "            predicate=proposition.predicate,\n",
    "            boolean=True if answer[0] == 'yes' else False,\n",
    "            weight=answer[1]\n",
    "        )\n",
    "    \n",
    "    def maxSat(self, beliefs: List[Proposition]):\n",
    "        \"\"\"Run MaxSAT solver considering 'beliefs' and constraints\n",
    "        \n",
    "        Args:\n",
    "            beliefs: List of propositions\n",
    "        \n",
    "        Returns:\n",
    "            new_beliefs: List of modified beliefs to ensure maximum satisfiability\n",
    "        \"\"\"\n",
    "        optim = Optimize()\n",
    "\n",
    "        belief_bools = {}\n",
    "        belief_props = {}\n",
    "        \n",
    "        subjects = set()\n",
    "\n",
    "        for prop in beliefs:\n",
    "            subjects.add(prop.subject)\n",
    "            sentence = prop.sentence\n",
    "            if sentence not in belief_bools:\n",
    "                belief_bools[sentence] = Bool(sentence)\n",
    "                belief_props[sentence] = prop\n",
    "            if prop.boolean == True:\n",
    "                optim.add_soft(belief_bools[sentence], prop.weight)\n",
    "            else:\n",
    "                optim.add_soft(Not(belief_bools[sentence]), prop.weight)\n",
    "\n",
    "        for constraint in self.constraints:\n",
    "            for subject in subjects:\n",
    "                src_sent = constraint.src_predicate.substitute(subject)\n",
    "                dest_sent = constraint.dest_predicate.substitute(subject)\n",
    "\n",
    "                if (src_sent not in self.beliefs) or (dest_sent not in self.beliefs):\n",
    "                    continue\n",
    "\n",
    "                src_bool = belief_bools[src_sent] if src_sent in belief_bools else Bool(src_sent)\n",
    "                dest_bool = belief_bools[dest_sent] if dest_sent in belief_bools else Bool(dest_sent)\n",
    "\n",
    "                if constraint.implication == \"yes_yes\":\n",
    "                    optim.add_soft(Implies(src_bool, dest_bool), constraint.weight)\n",
    "                elif constraint.implication == \"yes_no\":\n",
    "                    optim.add_soft(Implies(src_bool, Not(dest_bool)), constraint.weight)\n",
    "                elif constraint.implication == \"no_yes\":\n",
    "                    optim.add_soft(Implies(Not(src_bool), src_bool), constraint.weight)\n",
    "                elif constraint.implication == \"no_no\":\n",
    "                    optim.add_soft(Implies(Not(src_bool), Not(dest_bool)), constraint.weight)\n",
    "\n",
    "        optim.check()\n",
    "        mod = optim.model()\n",
    "\n",
    "        new_beliefs = copy.deepcopy(beliefs)\n",
    "        for prop in new_beliefs:\n",
    "            sentence = prop.sentence\n",
    "            prop.boolean = mod.evaluate(belief_bools[sentence])\n",
    "        \n",
    "        return new_beliefs\n",
    "\n",
    "    def feedback(self, proposition: Proposition, feedback_type=FeedbackType.RELEVANT):\n",
    "        \"\"\"Returns feedback beliefs corresponding to the given proposition using one of multiple strategies.\"\"\"\n",
    "        \n",
    "        if feedback_type == FeedbackType.ON_TOPIC_RANDOM:\n",
    "            on_topic_beliefs = self.get_beliefs_by_subject(proposition.subject)\n",
    "            return list(np.random.choice(on_topic_beliefs, min(self.num_random_on_topic_beliefs, len(on_topic_beliefs)), replace=False))\n",
    "\n",
    "        elif feedback_type == FeedbackType.RELEVANT:\n",
    "            # Sorting according to descending order\n",
    "            clashing_beliefs = sorted(self.get_clashing_beliefs(proposition), key=lambda prop: -prop.weight)\n",
    "            if len(clashing_beliefs) < self.num_relevant_beliefs:\n",
    "                clashing_beliefs += list(self.beliefs.values())[:self.num_relevant_beliefs - len(clashing_beliefs)]\n",
    "            return clashing_beliefs[:self.num_relevant_beliefs]\n",
    "            \n",
    "\n",
    "    def get_clashing_beliefs(self, proposition: Proposition):\n",
    "        \"\"\"Returns a list of beliefs present in the model that are inconsistent with the given proposition\"\"\"\n",
    "        \n",
    "        subject = proposition.subject\n",
    "        clashing_beliefs = []\n",
    "\n",
    "        visited_nodes = set()\n",
    "        def dfs(predicate: Predicate, expected_truth: bool):\n",
    "            visited_nodes.add(predicate.str_rep)\n",
    "            sentence = predicate.substitute(subject)\n",
    "            if self.beliefs[sentence].boolean != expected_truth:\n",
    "                clashing_beliefs.append(self.beliefs[sentence])\n",
    "            for constraint in self.links[predicate.str_rep]:\n",
    "                if not constraint.dest_predicate.str_rep in visited_nodes:\n",
    "                    if constraint.implication == \"yes_yes\" and expected_truth == True:\n",
    "                        dfs(constraint.dest_predicate, True)\n",
    "                    elif constraint.implication == \"yes_no\" and expected_truth == True:\n",
    "                        dfs(constraint.dest_predicate, False)\n",
    "                    elif constraint.implication == \"no_yes\" and expected_truth == False:\n",
    "                        dfs(constraint.dest_predicate, True)\n",
    "                    elif constraint.implication == \"no_no\" and expected_truth == False:\n",
    "                        dfs(constraint.dest_predicate, False)\n",
    "\n",
    "        return clashing_beliefs\n",
    "\n",
    "    def calculate_consistency(self):\n",
    "        \n",
    "        violation_criteria = {\n",
    "            \"yes_yes\": (True, False),\n",
    "            \"yes_no\": (True, True),\n",
    "            \"no_yes\": (False, False),\n",
    "            \"no_no\": (False, True)\n",
    "        }\n",
    "\n",
    "        violated_constraints = 0\n",
    "        valid_constraints = 0\n",
    "\n",
    "        for src_sentence in self.beliefs:\n",
    "            src_prop = self.beliefs[src_sentence]\n",
    "            \n",
    "            for constraint in self.links[src_prop.predicate.str_rep]:    \n",
    "                dest_sentence = constraint.dest_predicate.substitute(src_prop.subject)\n",
    "\n",
    "                if (src_sentence in self.beliefs) and (dest_sentence in self.beliefs):\n",
    "                    valid_constraints += 1\n",
    "                    dest_prop = self.beliefs[dest_sentence]\n",
    "                    if (src_prop.boolean, dest_prop.boolean) == violation_criteria[constraint.implication]:\n",
    "                        violated_constraints += 1\n",
    "\n",
    "        if valid_constraints == 0:\n",
    "            return 0\n",
    "        return 1 - (violated_constraints/valid_constraints)\n",
    "\n",
    "    def calculate_f1(self, fact_props):\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        tn = 0\n",
    "        for prop in fact_props:\n",
    "            prediction = self.beliefs[prop.sentence].boolean\n",
    "            label = prop.boolean\n",
    "            if prediction == True and label == True:\n",
    "                tp += 1\n",
    "            elif prediction == True and label == False:\n",
    "                fp += 1\n",
    "            elif prediction == False and label == True:\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "\n",
    "        return 2*precision*recall / (precision + recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = []\n",
    "for subject in fact_data.keys():\n",
    "    for predicate_str_rep in fact_data[subject]:\n",
    "        prop = Proposition(\n",
    "            subject=subject,\n",
    "            predicate=Predicate(predicate_str_rep)\n",
    "        )\n",
    "        facts.append(prop)\n",
    "random.shuffle(facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n"
     ]
    }
   ],
   "source": [
    "batch_size = len(facts) // 100\n",
    "print(batch_size)\n",
    "fact_batches = [facts[batch_size*i:batch_size*(i+1)] for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbb = LMBB(model=model, tokenizer=tokenizer, raw_constraints=constraint_data['links'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8571428571428572\n",
      "0.8947368421052632\n",
      "0.9019607843137255\n",
      "0.9603960396039604\n",
      "0.9807692307692307\n",
      "0.9849246231155779\n",
      "0.9776119402985075\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/abhijit/beliefbank/beliefbank.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     lmbb\u001b[39m.\u001b[39;49madd_belief_set(fact_batches[i])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(lmbb\u001b[39m.\u001b[39mcalculate_consistency())\n",
      "\u001b[1;32m/home/abhijit/beliefbank/beliefbank.ipynb Cell 12\u001b[0m in \u001b[0;36mLMBB.add_belief_set\u001b[0;34m(self, propositions, constraint_solving, with_feedback, feedback_type)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=176'>177</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_belief_set\u001b[39m(\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=177'>178</a>\u001b[0m     \u001b[39mself\u001b[39m, \n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=178'>179</a>\u001b[0m     propositions: List[Proposition],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=181'>182</a>\u001b[0m     feedback_type: FeedbackType \u001b[39m=\u001b[39m FeedbackType\u001b[39m.\u001b[39mRELEVANT\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=182'>183</a>\u001b[0m ):\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=183'>184</a>\u001b[0m     \u001b[39m\"\"\"Adds a set of proposition to the systems existing set of beliefs\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=184'>185</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=185'>186</a>\u001b[0m \u001b[39m        propositions: List of new propositions to add\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=188'>189</a>\u001b[0m \u001b[39m        feedback_type: RELEVANT / ON_TOPIC_RANDOM\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=189'>190</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=190'>191</a>\u001b[0m     propositions \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery(proposition, with_feedback, feedback_type) \u001b[39mfor\u001b[39;00m proposition \u001b[39min\u001b[39;00m propositions]\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=192'>193</a>\u001b[0m     \u001b[39m# Optional constraint solving\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=193'>194</a>\u001b[0m     \u001b[39mif\u001b[39;00m constraint_solving:\n",
      "\u001b[1;32m/home/abhijit/beliefbank/beliefbank.ipynb Cell 12\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=176'>177</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_belief_set\u001b[39m(\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=177'>178</a>\u001b[0m     \u001b[39mself\u001b[39m, \n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=178'>179</a>\u001b[0m     propositions: List[Proposition],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=181'>182</a>\u001b[0m     feedback_type: FeedbackType \u001b[39m=\u001b[39m FeedbackType\u001b[39m.\u001b[39mRELEVANT\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=182'>183</a>\u001b[0m ):\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=183'>184</a>\u001b[0m     \u001b[39m\"\"\"Adds a set of proposition to the systems existing set of beliefs\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=184'>185</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=185'>186</a>\u001b[0m \u001b[39m        propositions: List of new propositions to add\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=188'>189</a>\u001b[0m \u001b[39m        feedback_type: RELEVANT / ON_TOPIC_RANDOM\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=189'>190</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=190'>191</a>\u001b[0m     propositions \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquery(proposition, with_feedback, feedback_type) \u001b[39mfor\u001b[39;00m proposition \u001b[39min\u001b[39;00m propositions]\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=192'>193</a>\u001b[0m     \u001b[39m# Optional constraint solving\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=193'>194</a>\u001b[0m     \u001b[39mif\u001b[39;00m constraint_solving:\n",
      "\u001b[1;32m/home/abhijit/beliefbank/beliefbank.ipynb Cell 12\u001b[0m in \u001b[0;36mLMBB.query\u001b[0;34m(self, proposition, with_feedback, feedback_type)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=224'>225</a>\u001b[0m options \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39myes\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mno\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=226'>227</a>\u001b[0m raw_input \u001b[39m=\u001b[39m get_raw_input(question, options)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=227'>228</a>\u001b[0m scores \u001b[39m=\u001b[39m get_scores(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer, raw_input, options)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=228'>229</a>\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(scores, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m1\u001b[39m])\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=230'>231</a>\u001b[0m \u001b[39mreturn\u001b[39;00m Proposition(\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=231'>232</a>\u001b[0m     subject\u001b[39m=\u001b[39mproposition\u001b[39m.\u001b[39msubject,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=232'>233</a>\u001b[0m     predicate\u001b[39m=\u001b[39mproposition\u001b[39m.\u001b[39mpredicate,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=233'>234</a>\u001b[0m     boolean\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m answer[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39myes\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=234'>235</a>\u001b[0m     weight\u001b[39m=\u001b[39manswer[\u001b[39m1\u001b[39m]\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=235'>236</a>\u001b[0m )\n",
      "\u001b[1;32m/home/abhijit/beliefbank/beliefbank.ipynb Cell 12\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(model, tokenizer, raw_input, output_options)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m option \u001b[39min\u001b[39;00m output_options:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     output_ids \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode(option, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     res \u001b[39m=\u001b[39m model(input_ids, labels\u001b[39m=\u001b[39;49moutput_ids, return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     score \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39mres\u001b[39m.\u001b[39mloss)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abhijit/beliefbank/beliefbank.ipynb#Y116sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     output_scores\u001b[39m.\u001b[39mappend((option, score\u001b[39m.\u001b[39mnumpy()))\n",
      "File \u001b[0;32m~/coursework/advnlp/advnlp/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/coursework/advnlp/advnlp/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:1602\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1599\u001b[0m \u001b[39m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m \u001b[39mif\u001b[39;00m encoder_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1601\u001b[0m     \u001b[39m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[0;32m-> 1602\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1603\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1604\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1605\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1606\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1607\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1608\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1609\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1610\u001b[0m     )\n\u001b[1;32m   1611\u001b[0m \u001b[39melif\u001b[39;00m return_dict \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[1;32m   1612\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1613\u001b[0m         last_hidden_state\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m0\u001b[39m],\n\u001b[1;32m   1614\u001b[0m         hidden_states\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1615\u001b[0m         attentions\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1616\u001b[0m     )\n",
      "File \u001b[0;32m~/coursework/advnlp/advnlp/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/coursework/advnlp/advnlp/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:1035\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     layer_outputs \u001b[39m=\u001b[39m checkpoint(\n\u001b[1;32m   1023\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   1024\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[39mNone\u001b[39;00m,  \u001b[39m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m     )\n\u001b[1;32m   1034\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1035\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m   1036\u001b[0m         hidden_states,\n\u001b[1;32m   1037\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1038\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m   1039\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1040\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1041\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[1;32m   1042\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m   1043\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m   1044\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1045\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1046\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1047\u001b[0m     )\n\u001b[1;32m   1049\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/coursework/advnlp/advnlp/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/coursework/advnlp/advnlp/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:666\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    664\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 666\u001b[0m self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m0\u001b[39;49m](\n\u001b[1;32m    667\u001b[0m     hidden_states,\n\u001b[1;32m    668\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    669\u001b[0m     position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    670\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    671\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    672\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    673\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    674\u001b[0m )\n\u001b[1;32m    675\u001b[0m hidden_states, present_key_value_state \u001b[39m=\u001b[39m self_attention_outputs[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    676\u001b[0m attention_outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m2\u001b[39m:]  \u001b[39m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m~/coursework/advnlp/advnlp/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/coursework/advnlp/advnlp/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:572\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    562\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    563\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    569\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    570\u001b[0m ):\n\u001b[1;32m    571\u001b[0m     normed_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 572\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSelfAttention(\n\u001b[1;32m    573\u001b[0m         normed_hidden_states,\n\u001b[1;32m    574\u001b[0m         mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    575\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    576\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    577\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    578\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    579\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[1;32m    581\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_output[\u001b[39m0\u001b[39m])\n\u001b[1;32m    582\u001b[0m     outputs \u001b[39m=\u001b[39m (hidden_states,) \u001b[39m+\u001b[39m attention_output[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/coursework/advnlp/advnlp/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/coursework/advnlp/advnlp/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:544\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    541\u001b[0m     attn_weights \u001b[39m=\u001b[39m attn_weights \u001b[39m*\u001b[39m layer_head_mask\n\u001b[1;32m    543\u001b[0m attn_output \u001b[39m=\u001b[39m unshape(torch\u001b[39m.\u001b[39mmatmul(attn_weights, value_states))  \u001b[39m# (batch_size, seq_length, dim)\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mo(attn_output)\n\u001b[1;32m    546\u001b[0m present_key_value_state \u001b[39m=\u001b[39m (key_states, value_states) \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_decoder \u001b[39mand\u001b[39;00m use_cache) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    547\u001b[0m outputs \u001b[39m=\u001b[39m (attn_output,) \u001b[39m+\u001b[39m (present_key_value_state,) \u001b[39m+\u001b[39m (position_bias,)\n",
      "File \u001b[0;32m~/coursework/advnlp/advnlp/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/coursework/advnlp/advnlp/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    lmbb.add_belief_set(fact_batches[i])\n",
    "    print(lmbb.calculate_consistency())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmbb.calculate_consistency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_facts = [fact for fact in facts if fact.boolean == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root: Is a starling a terrestrial organism? \n",
      " (A) yes (B) no\n",
      "DEBUG:root:[('yes', array(0.2710582, dtype=float32)), ('no', array(0.9625627, dtype=float32))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(starling,IsA,terrestrial organism, False, 0.962)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = random.randint(0, len(true_facts))\n",
    "print(idx)\n",
    "lmbb.query(true_facts[idx], with_feedback=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('advnlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22bb8309d38f1e65544d46771276df01ff94c6adf407f8023f86ac86fc1d49c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
