{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "from enum import Enum\n",
    "from typing import List, Dict\n",
    "import copy\n",
    "import json\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.031552791595458984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 21,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 791656,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6581241f7424eba9ceed7a70e19fff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.026134967803955078,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 21,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1786,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c3e38c88344d648baa20235c63fe3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.027059555053710938,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 21,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 2145,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690d1a105ec941afb319b62a34d05604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.09k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.027360200881958008,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 21,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1355,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29fd7b603a0c4ef5bc142a7d12dd27a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.026805400848388672,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 21,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 242087757,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c851ba26b9240d8b124b233fac7237f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/231M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"allenai/unifiedqa-v2-t5-small-1251000\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/constraints_v2.json', 'r') as f:\n",
    "    constraint_data = json.load(f)\n",
    "\n",
    "with open('./data/calibration_facts.json', 'r') as f:\n",
    "    fact_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(model, tokenizer, raw_input, output_options):\n",
    "    output_scores = []\n",
    "    with torch.no_grad():\n",
    "        input_ids = tokenizer.encode(raw_input, return_tensors=\"pt\")\n",
    "        for option in output_options:\n",
    "            output_ids = tokenizer.encode(option, return_tensors=\"pt\")\n",
    "            res = model(input_ids, labels=output_ids, return_dict=True)\n",
    "            score = torch.exp(-res.loss)\n",
    "            output_scores.append((option, score.numpy()))\n",
    "    return output_scores\n",
    "\n",
    "def get_raw_input(question, options):\n",
    "    raw_input = question + ' \\n'\n",
    "    for option_num, option in zip(list(string.ascii_uppercase), options):\n",
    "        raw_input += f' ({option_num}) {option}'\n",
    "    return raw_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackType(Enum):\n",
    "    RELEVANT = 0\n",
    "    ON_TOPIC_RANDOM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_PRECISION = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predicate():\n",
    "    \"\"\"A predicate is a generalized sentence which can be substituted with entities.\n",
    "    Example 'IsA,dog' is a predicate in which if we substitute the entity 'poodle',\n",
    "    we get the sentence 'A poodle is a dog'.\n",
    "\n",
    "    Args:\n",
    "        str_rep: String representation of predicate, ex 'IsA,mammal', 'HasA,tail'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, str_rep):\n",
    "        self.str_rep = str_rep\n",
    "        self.relation, self.object = str_rep.split(\",\")\n",
    "        if self.relation not in ['CapableOf', 'HasA', 'HasPart', 'HasProperty', 'IsA', 'MadeOf']:\n",
    "            raise Exception(f\"{self.relation} is an unsupported relation\")\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.relation},{self.object}\"\n",
    "\n",
    "    def substitute(self, subject):\n",
    "        \"\"\"Returns sentence, i.e. 'subject,relation,object' on substituting subject in\n",
    "        the predicate.\n",
    "        \"\"\"\n",
    "        return f\"{subject},{self.relation},{self.object}\"\n",
    "\n",
    "class Proposition():\n",
    "    \"\"\"A proposition, Can be a belief when present in a belief bank\n",
    "\n",
    "    Attributes:\n",
    "        subject: The subject of the proposition\n",
    "        predicate: The general predicate of the proposition in which the subject is substituted.\n",
    "        boolean: The Truth value of the sentence\n",
    "        weight: Optional attribute indicating the weight of the proposition. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        subject: str,\n",
    "        predicate: Predicate,\n",
    "        boolean: bool = True,\n",
    "        weight: float = -99999,\n",
    "    ):\n",
    "        self.subject = subject\n",
    "        self.predicate = predicate\n",
    "        self.boolean = boolean\n",
    "        self.weight = int(round(weight * (10**WEIGHT_PRECISION), WEIGHT_PRECISION))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"({self.sentence}, {self.boolean}, {self.weight / (10**WEIGHT_PRECISION)})\"\n",
    "\n",
    "    @property\n",
    "    def sentence(self):\n",
    "        return self.predicate.substitute(self.subject)\n",
    "\n",
    "    def get_nl_sentence(self):\n",
    "        \"\"\"Returns natural language sentence expressing the proposition\"\"\"\n",
    "        if self.predicate.relation == 'IsA':\n",
    "            return f\"{self.subject} is a {self.predicate.object}.\"\n",
    "        if self.predicate.relation == \"MadeOf\":\n",
    "            return f\"{self.subject} is made of {self.predicate.object}.\"\n",
    "        if self.predicate.relation == \"CapableOf\":\n",
    "            return f\"{self.subject} is capable of {self.predicate.object}.\"\n",
    "        if self.predicate.relation == \"HasA\":\n",
    "            return f\"{self.subject} has a {self.predicate.object}.\"\n",
    "        if self.predicate.relation == \"HasPart\":\n",
    "            return f\"A {self.predicate.object} is part of a {self.subject}.\"\n",
    "        if self.predicate.relation == \"HasProperty\":\n",
    "            return f\"{self.subject} has the property of being {self.predicate.object}.\"\n",
    "\n",
    "    def get_nl_question(self):\n",
    "        \"\"\"Returns natural language sentence asking the proposition\"\"\"\n",
    "        if self.predicate.relation == 'IsA':\n",
    "            return f\"Is a {self.subject} a {self.predicate.object}?\"\n",
    "        if self.predicate.relation == \"MadeOf\":\n",
    "            return f\"Is a {self.subject} made of {self.predicate.object}?\"\n",
    "        if self.predicate.relation == \"CapableOf\":\n",
    "            return f\"Is a {self.subject} capable of {self.predicate.object}?\"\n",
    "        if self.predicate.relation == \"HasA\":\n",
    "            return f\"Does a {self.subject} have a {self.predicate.object}?\"\n",
    "        if self.predicate.relation == \"HasPart\":\n",
    "            return f\"Is a {self.predicate.object} part of a {self.subject}?\"\n",
    "        if self.predicate.relation == \"HasProperty\":\n",
    "            return f\"Does {self.subject} have the property of being {self.predicate.object}?\"\n",
    "\n",
    "class Constraint():\n",
    "    \"\"\"Class for constraint\n",
    "    \n",
    "    Attributes:\n",
    "        src_predicate: The source predicate\n",
    "        dest_predicate: The destination predicate\n",
    "        weight: Penalty for violation of constraint\n",
    "        implication: Indicates the type of implication in the constraint (T->F, T->T, F->T, F->F)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_predicate: Predicate,\n",
    "        dest_predicate: Predicate,\n",
    "        weight: float,\n",
    "        implication: str\n",
    "    ):\n",
    "        self.src_predicate = src_predicate\n",
    "        self.dest_predicate = dest_predicate\n",
    "        self.weight = int(round(weight * (10**WEIGHT_PRECISION), WEIGHT_PRECISION))\n",
    "        self.implication = implication\n",
    "\n",
    "    @classmethod\n",
    "    def from_raw(cls, raw_link):\n",
    "        if raw_link['direction'] == 'forward':\n",
    "            src_predicate = raw_link['source']\n",
    "            dest_predicate = raw_link['target']\n",
    "        elif raw_link['direction'] == 'back':\n",
    "            src_predicate = raw_link['target']\n",
    "            dest_predicate = raw_link['source']\n",
    "\n",
    "        return Constraint(\n",
    "            src_predicate=Predicate(src_predicate),\n",
    "            dest_predicate=Predicate(dest_predicate),\n",
    "            weight=raw_link['score'],\n",
    "            implication=raw_link['weight']\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        s, d = self.implication.split('_')\n",
    "        return f\"Constraint(<{'¬' if s == 'no' else ''}{self.src_predicate.str_rep} ⟶ {'¬' if d == 'no' else ''}{self.dest_predicate.str_rep}>, {self.weight / {10**WEIGHT_PRECISION}})\"\n",
    "\n",
    "\n",
    "class LMBB():\n",
    "    \"\"\"Langauge Model + Belief Bank\"\"\"\n",
    "\n",
    "    def __init__(self, model, tokenizer, raw_constraints):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        self.constraints = [Constraint.from_raw(c) for c in raw_constraints]\n",
    "        self.links: Dict[str, List[Constraint]] = defaultdict(list)\n",
    "        for constraint in self.constraints:\n",
    "            self.links[constraint.src_predicate.str_rep].append(constraint)\n",
    "        \n",
    "        # Dictionary where the key is 'subject,relation,predicate' and value is a proposition\n",
    "        self.beliefs = dict()\n",
    "\n",
    "        # Feedback config\n",
    "        self.num_random_on_topic_beliefs = 3\n",
    "        self.num_relevant_beliefs = 3\n",
    "        \n",
    "    def get_beliefs_by_subject(self, subject):\n",
    "        subject_beliefs = [self.beliefs[key] for key in self.beliefs.keys() if key.split(\",\")[0] == subject]\n",
    "        return subject_beliefs\n",
    "\n",
    "#     def add_belief(\n",
    "#         self, \n",
    "#         proposition: Proposition,\n",
    "#         constraint_solving: bool = True,\n",
    "#         with_feedback: bool = True,\n",
    "#         feedback_type: FeedbackType = FeedbackType.RELEVANT\n",
    "#     ):\n",
    "#         \"\"\"Adds a single proposition to the systems existing set of beliefs\n",
    "#         Args:\n",
    "#             proposition: New proposition to add\n",
    "#             constraint_solving: Whether to use constraint solving or not\n",
    "#             with_feedback: Whether to use feedback or not\n",
    "#             feedback_type: RELEVANT / ON_TOPIC_RANDOM\n",
    "#         \"\"\"\n",
    "        \n",
    "#         # Get proposition after passing through language model with/without feedback\n",
    "#         proposition = self.query(proposition, with_feedback, feedback_type)\n",
    "\n",
    "#         # Optional constraint solving\n",
    "#         if constraint_solving:\n",
    "#             beliefs = list(self.beliefs.values())\n",
    "#             # beliefs.append(proposition)\n",
    "#             new_beliefs = self.maxSat(beliefs, [proposition])\n",
    "#         else:\n",
    "#             new_beliefs = [proposition]\n",
    "#         self.set_beliefs(new_beliefs)\n",
    "\n",
    "    def add_belief_set(\n",
    "        self, \n",
    "        propositions: List[Proposition],\n",
    "        constraint_solving: bool = True,\n",
    "        with_feedback: bool = True,\n",
    "        feedback_type: FeedbackType = FeedbackType.RELEVANT\n",
    "    ):\n",
    "        \"\"\"Adds a set of proposition to the systems existing set of beliefs\n",
    "        Args:\n",
    "            propositions: List of new propositions to add\n",
    "            constraint_solving: Whether to use constraint solving or not\n",
    "            with_feedback: Whether to use feedback or not\n",
    "            feedback_type: RELEVANT / ON_TOPIC_RANDOM\n",
    "        \"\"\"\n",
    "        propositions = [self.query(proposition, with_feedback, feedback_type) for proposition in propositions]\n",
    "        \n",
    "        # Optional constraint solving\n",
    "        beliefs = list(self.beliefs.values())\n",
    "        if constraint_solving:\n",
    "            # beliefs += propositions\n",
    "            new_beliefs = self.maxSat(beliefs, propositions)\n",
    "        else:\n",
    "            new_beliefs = beliefs + propositions\n",
    "        self.set_beliefs(new_beliefs)\n",
    "\n",
    "    def set_beliefs(self, new_beliefs):\n",
    "        for belief in new_beliefs:\n",
    "            self.beliefs[belief.sentence] = belief\n",
    "\n",
    "    def query(self, proposition: Proposition, with_feedback=True, feedback_type=FeedbackType.RELEVANT):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            proposition: the query to the LMBB system\n",
    "            with_feedback: Whether to use context from existing beliefs or not\n",
    "            feedback_type: RELEVANT / ON_TOPIC_RANDOM \n",
    "\n",
    "        Returns:\n",
    "            proposition: The updated proposition with truth value and weight\n",
    "        \"\"\"\n",
    "        \n",
    "        feedback_beliefs = []\n",
    "        if with_feedback:\n",
    "            feedback_beliefs = self.feedback(proposition, feedback_type)\n",
    "        feedback_string = \" \".join([belief.get_nl_sentence() for belief in feedback_beliefs])\n",
    "        question = feedback_string + ' ' + proposition.get_nl_question()\n",
    "\n",
    "        # TODO: Grammar model to refine the question\n",
    "        \n",
    "        options = ['yes', 'no']\n",
    "        \n",
    "        raw_input = get_raw_input(question, options)\n",
    "        scores = get_scores(self.model, self.tokenizer, raw_input, options)\n",
    "        answer = max(scores, key=lambda x: x[1])\n",
    "\n",
    "        return Proposition(\n",
    "            subject=proposition.subject,\n",
    "            predicate=proposition.predicate,\n",
    "            boolean=True if answer[0] == 'yes' else False,\n",
    "            weight=answer[1]\n",
    "        )\n",
    "    \n",
    "    def maxSat(self, old_beliefs: List[Proposition], new_beliefs: List[Proposition], lamda=1.5):\n",
    "        \"\"\"Run MaxSAT solver considering 'beliefs' and constraints\n",
    "        \n",
    "        Args:\n",
    "            old_beliefs: List of pre-existing beliefs\n",
    "            new_beliefs: List of new beliefs\n",
    "            lamda: Multiplier for new belief scores in SAT solver\n",
    "        \n",
    "        Returns:\n",
    "            new_beliefs: List of modified beliefs to ensure maximum satisfiability\n",
    "        \"\"\"\n",
    "        optim = Optimize()\n",
    "\n",
    "        belief_bools = {}\n",
    "        belief_props = {}\n",
    "        \n",
    "        subjects = set()\n",
    "\n",
    "        for prop in old_beliefs:\n",
    "            subjects.add(prop.subject)\n",
    "            sentence = prop.sentence\n",
    "            if sentence not in belief_bools:\n",
    "                belief_bools[sentence] = Bool(sentence)\n",
    "                belief_props[sentence] = prop\n",
    "            if prop.boolean == True:\n",
    "                optim.add_soft(belief_bools[sentence], prop.weight)\n",
    "            else:\n",
    "                optim.add_soft(Not(belief_bools[sentence]), prop.weight)\n",
    "        \n",
    "        for prop in new_beliefs:\n",
    "            subjects.add(prop.subject)\n",
    "            sentence = prop.sentence\n",
    "            if sentence not in belief_bools:\n",
    "                belief_bools[sentence] = Bool(sentence)\n",
    "                belief_props[sentence] = prop\n",
    "            if prop.boolean == True:\n",
    "                optim.add_soft(belief_bools[sentence], lamda * prop.weight)\n",
    "            else:\n",
    "                optim.add_soft(Not(belief_bools[sentence]), lamda * prop.weight)\n",
    "\n",
    "        for constraint in self.constraints:\n",
    "            for subject in subjects:\n",
    "                src_sent = constraint.src_predicate.substitute(subject)\n",
    "                dest_sent = constraint.dest_predicate.substitute(subject)\n",
    "\n",
    "                if (src_sent not in self.beliefs) or (dest_sent not in self.beliefs):\n",
    "                    continue\n",
    "\n",
    "                src_bool = belief_bools[src_sent] if src_sent in belief_bools else Bool(src_sent)\n",
    "                dest_bool = belief_bools[dest_sent] if dest_sent in belief_bools else Bool(dest_sent)\n",
    "\n",
    "                if constraint.implication == \"yes_yes\":\n",
    "                    optim.add_soft(Implies(src_bool, dest_bool), constraint.weight)\n",
    "                elif constraint.implication == \"yes_no\":\n",
    "                    optim.add_soft(Implies(src_bool, Not(dest_bool)), constraint.weight)\n",
    "                elif constraint.implication == \"no_yes\":\n",
    "                    optim.add_soft(Implies(Not(src_bool), src_bool), constraint.weight)\n",
    "                elif constraint.implication == \"no_no\":\n",
    "                    optim.add_soft(Implies(Not(src_bool), Not(dest_bool)), constraint.weight)\n",
    "\n",
    "        optim.check()\n",
    "        mod = optim.model()\n",
    "\n",
    "        new_beliefs = copy.deepcopy(old_beliefs + new_beliefs)\n",
    "        for prop in new_beliefs:\n",
    "            sentence = prop.sentence\n",
    "            prop.boolean = mod.evaluate(belief_bools[sentence])\n",
    "        \n",
    "        return new_beliefs\n",
    "\n",
    "    def feedback(self, proposition: Proposition, feedback_type=FeedbackType.RELEVANT):\n",
    "        \"\"\"Returns feedback beliefs corresponding to the given proposition using one of multiple strategies.\"\"\"\n",
    "        \n",
    "        if feedback_type == FeedbackType.ON_TOPIC_RANDOM:\n",
    "            on_topic_beliefs = self.get_beliefs_by_subject(proposition.subject)\n",
    "            return list(np.random.choice(on_topic_beliefs, min(self.num_random_on_topic_beliefs, len(on_topic_beliefs)), replace=False))\n",
    "\n",
    "        elif feedback_type == FeedbackType.RELEVANT:\n",
    "            # Sorting according to descending order\n",
    "            clashing_beliefs = sorted(self.get_clashing_beliefs(proposition), key=lambda prop: -prop.weight)\n",
    "            if len(clashing_beliefs) < self.num_relevant_beliefs:\n",
    "                clashing_beliefs += list(self.beliefs.values())[:self.num_relevant_beliefs - len(clashing_beliefs)]\n",
    "            return clashing_beliefs[:self.num_relevant_beliefs]\n",
    "            \n",
    "\n",
    "    def get_clashing_beliefs(self, proposition: Proposition):\n",
    "        \"\"\"Returns a list of beliefs present in the model that are inconsistent with the given proposition\"\"\"\n",
    "        \n",
    "        subject = proposition.subject\n",
    "        clashing_beliefs = []\n",
    "\n",
    "        visited_nodes = set()\n",
    "        def dfs(predicate: Predicate, expected_truth: bool):\n",
    "            visited_nodes.add(predicate.str_rep)\n",
    "            sentence = predicate.substitute(subject)\n",
    "            if self.beliefs[sentence].boolean != expected_truth:\n",
    "                clashing_beliefs.append(self.beliefs[sentence])\n",
    "            for constraint in self.links[predicate.str_rep]:\n",
    "                if not constraint.dest_predicate.str_rep in visited_nodes:\n",
    "                    if constraint.implication == \"yes_yes\" and expected_truth == True:\n",
    "                        dfs(constraint.dest_predicate, True)\n",
    "                    elif constraint.implication == \"yes_no\" and expected_truth == True:\n",
    "                        dfs(constraint.dest_predicate, False)\n",
    "                    elif constraint.implication == \"no_yes\" and expected_truth == False:\n",
    "                        dfs(constraint.dest_predicate, True)\n",
    "                    elif constraint.implication == \"no_no\" and expected_truth == False:\n",
    "                        dfs(constraint.dest_predicate, False)\n",
    "\n",
    "        return clashing_beliefs\n",
    "\n",
    "    def calculate_consistency(self):\n",
    "        \n",
    "        violation_criteria = {\n",
    "            \"yes_yes\": (True, False),\n",
    "            \"yes_no\": (True, True),\n",
    "            \"no_yes\": (False, False),\n",
    "            \"no_no\": (False, True)\n",
    "        }\n",
    "\n",
    "        violated_constraints = 0\n",
    "        valid_constraints = 0\n",
    "\n",
    "        for src_sentence in self.beliefs:\n",
    "            src_prop = self.beliefs[src_sentence]\n",
    "            \n",
    "            for constraint in self.links[src_prop.predicate.str_rep]:    \n",
    "                dest_sentence = constraint.dest_predicate.substitute(src_prop.subject)\n",
    "\n",
    "                if (src_sentence in self.beliefs) and (dest_sentence in self.beliefs):\n",
    "                    valid_constraints += 1\n",
    "                    dest_prop = self.beliefs[dest_sentence]\n",
    "                    if (src_prop.boolean, dest_prop.boolean) == violation_criteria[constraint.implication]:\n",
    "                        violated_constraints += 1\n",
    "\n",
    "        if valid_constraints == 0:\n",
    "            return 0\n",
    "        return 1 - (violated_constraints/valid_constraints)\n",
    "\n",
    "    def calculate_f1(self, fact_props):\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        tn = 0\n",
    "        for prop in fact_props:\n",
    "            prediction = self.beliefs[prop.sentence].boolean\n",
    "            label = prop.boolean\n",
    "            if prediction == True and label == True:\n",
    "                tp += 1\n",
    "            elif prediction == True and label == False:\n",
    "                fp += 1\n",
    "            elif prediction == False and label == True:\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "\n",
    "        return 2*precision*recall / (precision + recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = []\n",
    "for subject in fact_data.keys():\n",
    "    for predicate_str_rep in fact_data[subject]:\n",
    "        prop = Proposition(\n",
    "            subject=subject,\n",
    "            predicate=Predicate(predicate_str_rep)\n",
    "        )\n",
    "        facts.append(prop)\n",
    "random.shuffle(facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n"
     ]
    }
   ],
   "source": [
    "batch_size = len(facts) // 100\n",
    "print(batch_size)\n",
    "fact_batches = [facts[batch_size*i:batch_size*(i+1)] for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbb = LMBB(model=model, tokenizer=tokenizer, raw_constraints=constraint_data['links'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 : F1 = 0.7142857142857143, consistency = 0.8\n",
      "Batch 2 : F1 = 0.7142857142857143, consistency = 0.631578947368421\n",
      "Batch 3 : F1 = 0.6965517241379311, consistency = 0.7906976744186046\n",
      "Batch 4 : F1 = 0.6875000000000001, consistency = 0.8089887640449438\n",
      "Batch 5 : F1 = 0.6820083682008369, consistency = 0.8169014084507042\n",
      "Batch 6 : F1 = 0.6909090909090909, consistency = 0.7912621359223301\n",
      "Batch 7 : F1 = 0.6923647146034099, consistency = 0.78839590443686\n",
      "Batch 8 : F1 = 0.6959896507115136, consistency = 0.7929155313351499\n",
      "Batch 9 : F1 = 0.6844547563805105, consistency = 0.790356394129979\n",
      "Batch 10 : F1 = 0.691588785046729, consistency = 0.7775831873905429\n",
      "Batch 11 : F1 = 0.695529411764706, consistency = 0.7651296829971181\n",
      "Batch 12 : F1 = 0.6954270923209663, consistency = 0.7674418604651163\n",
      "Batch 13 : F1 = 0.6948207171314742, consistency = 0.7681451612903226\n",
      "Batch 14 : F1 = 0.690423162583519, consistency = 0.768695652173913\n",
      "Batch 15 : F1 = 0.691588785046729, consistency = 0.7711552612214864\n",
      "Batch 16 : F1 = 0.6947232113952736, consistency = 0.7648221343873518\n",
      "Batch 17 : F1 = 0.6958904109589041, consistency = 0.7652582159624413\n",
      "Batch 18 : F1 = 0.6958021851638874, consistency = 0.7687246963562753\n",
      "Batch 19 : F1 = 0.696078431372549, consistency = 0.7684548372306281\n",
      "Batch 20 : F1 = 0.6959896507115136, consistency = 0.7687813021702838\n",
      "Batch 21 : F1 = 0.6939782823297137, consistency = 0.7663903541823662\n",
      "Batch 22 : F1 = 0.6899810964083175, consistency = 0.7735593220338983\n",
      "Batch 23 : F1 = 0.6910569105691057, consistency = 0.770625\n",
      "Batch 24 : F1 = 0.6934543097861309, consistency = 0.7673410404624277\n",
      "Batch 25 : F1 = 0.6959221693231215, consistency = 0.7662234042553191\n",
      "Batch 26 : F1 = 0.6953405017921147, consistency = 0.7708333333333334\n",
      "Batch 27 : F1 = 0.6968013790461598, consistency = 0.7715794306703397\n",
      "Batch 28 : F1 = 0.6945420906567993, consistency = 0.7741166269239107\n",
      "Batch 29 : F1 = 0.6950000000000001, consistency = 0.7760704773611965\n",
      "Batch 30 : F1 = 0.6920415224913494, consistency = 0.775576923076923\n",
      "Batch 31 : F1 = 0.6912380633271904, consistency = 0.7759493670886076\n",
      "Batch 32 : F1 = 0.6919708029197079, consistency = 0.7752864972595914\n",
      "Batch 33 : F1 = 0.6920415224913494, consistency = 0.7757082485521991\n",
      "Batch 34 : F1 = 0.6937033084311633, consistency = 0.776570757486788\n",
      "Batch 35 : F1 = 0.692558553216721, consistency = 0.7810128328963709\n",
      "Batch 36 : F1 = 0.693171996542783, consistency = 0.7832784726793943\n",
      "Batch 37 : F1 = 0.6928361138370952, consistency = 0.7826356205102799\n",
      "Batch 38 : F1 = 0.6934097421203438, consistency = 0.7806504445484324\n",
      "Batch 39 : F1 = 0.6922155688622755, consistency = 0.778592864288096\n",
      "Batch 40 : F1 = 0.6932849364791289, consistency = 0.777037037037037\n",
      "Batch 41 : F1 = 0.6929791271347249, consistency = 0.7761178964368628\n",
      "Batch 42 : F1 = 0.6946225949679329, consistency = 0.775084175084175\n",
      "Batch 43 : F1 = 0.6961857778847311, consistency = 0.773581429624171\n",
      "Batch 44 : F1 = 0.696142991533396, consistency = 0.7719685595690188\n",
      "Batch 45 : F1 = 0.6959521619135235, consistency = 0.7714309892527714\n",
      "Batch 46 : F1 = 0.6965028674238165, consistency = 0.7735574591886213\n",
      "Batch 47 : F1 = 0.6955947136563877, consistency = 0.7753132539497237\n",
      "Batch 48 : F1 = 0.6961302145090007, consistency = 0.7743016759776536\n",
      "Batch 49 : F1 = 0.6962305986696231, consistency = 0.7739367424514093\n",
      "Batch 50 : F1 = 0.697135766725261, consistency = 0.7746400885935769\n",
      "Batch 51 : F1 = 0.697080291970803, consistency = 0.7767531347442447\n",
      "Batch 52 : F1 = 0.6979332273449921, consistency = 0.7758401221995926\n",
      "Batch 53 : F1 = 0.698626132709734, consistency = 0.7744434878858689\n",
      "Batch 54 : F1 = 0.697799043062201, consistency = 0.7748799715488116\n",
      "Batch 55 : F1 = 0.6966334399097235, consistency = 0.7763478655252565\n",
      "Batch 56 : F1 = 0.6967122275581824, consistency = 0.777479304862672\n",
      "Batch 57 : F1 = 0.6967882416984214, consistency = 0.7767488623134723\n",
      "Batch 58 : F1 = 0.6963967178023547, consistency = 0.7786139217979356\n",
      "Batch 59 : F1 = 0.696589813272552, consistency = 0.7780341712490181\n",
      "Batch 60 : F1 = 0.6983471074380165, consistency = 0.7763239282485607\n",
      "Batch 61 : F1 = 0.6986115814426007, consistency = 0.7762728983976861\n",
      "Batch 62 : F1 = 0.6984338553815395, consistency = 0.773643686857448\n",
      "Batch 63 : F1 = 0.6977278320072184, consistency = 0.7737853595335781\n",
      "Batch 64 : F1 = 0.6975692481628039, consistency = 0.7722951371361265\n",
      "Batch 65 : F1 = 0.6972083035075162, consistency = 0.7736064171993974\n",
      "Batch 66 : F1 = 0.6975724353954581, consistency = 0.7726736411547235\n",
      "Batch 67 : F1 = 0.6984273820536541, consistency = 0.7708309389725319\n",
      "Batch 68 : F1 = 0.6986634264884569, consistency = 0.7710744724403588\n",
      "Batch 69 : F1 = 0.6986004041613652, consistency = 0.7704751909087619\n",
      "Batch 70 : F1 = 0.6991150442477877, consistency = 0.7701764892380315\n",
      "Batch 71 : F1 = 0.6989528795811518, consistency = 0.7706368531156761\n",
      "Batch 72 : F1 = 0.6988884904983865, consistency = 0.770112254443405\n",
      "Batch 73 : F1 = 0.698641765704584, consistency = 0.770099279735254\n",
      "Batch 74 : F1 = 0.6990372540812055, consistency = 0.7700160695717931\n",
      "Batch 75 : F1 = 0.6991534173033244, consistency = 0.7700644765121277\n",
      "Batch 76 : F1 = 0.6990897975818503, consistency = 0.7696937034042935\n",
      "Batch 77 : F1 = 0.6989405927316615, consistency = 0.7706392733815037\n",
      "Batch 78 : F1 = 0.6987951807228916, consistency = 0.7712085173858874\n",
      "Batch 79 : F1 = 0.6992486115648481, consistency = 0.7697019867549669\n",
      "Batch 80 : F1 = 0.699522642239711, consistency = 0.7692680823542093\n",
      "Batch 81 : F1 = 0.6994584262503982, consistency = 0.7701149425287357\n",
      "Batch 82 : F1 = 0.6989863375936536, consistency = 0.7708065593995785\n",
      "Batch 83 : F1 = 0.6982012821310761, consistency = 0.772291671906834\n",
      "Batch 84 : F1 = 0.6985551798339994, consistency = 0.7710568866676466\n",
      "Batch 85 : F1 = 0.6982680036463081, consistency = 0.7715565777809722\n",
      "Batch 86 : F1 = 0.6979091564527758, consistency = 0.7706970659689778\n",
      "Batch 87 : F1 = 0.6977904490377762, consistency = 0.7701083856246435\n",
      "Batch 88 : F1 = 0.69798027242837, consistency = 0.7707655992517704\n",
      "Batch 89 : F1 = 0.6984679665738162, consistency = 0.7706230421162548\n",
      "Batch 90 : F1 = 0.6984218077474892, consistency = 0.7710622319885648\n",
      "Batch 91 : F1 = 0.6980071538068472, consistency = 0.7707147177209118\n",
      "Batch 92 : F1 = 0.6982594048287479, consistency = 0.7711128328507931\n",
      "Batch 93 : F1 = 0.6985061365024712, consistency = 0.7719388665331932\n",
      "Batch 94 : F1 = 0.6988904756673623, consistency = 0.7722120871016575\n",
      "Batch 95 : F1 = 0.6986301369863014, consistency = 0.7730215553355169\n",
      "Batch 96 : F1 = 0.6987251896078748, consistency = 0.7730236197004694\n",
      "Batch 97 : F1 = 0.6986104456157164, consistency = 0.7727612962117755\n",
      "Batch 98 : F1 = 0.6982236044488958, consistency = 0.7731379600307731\n",
      "Batch 99 : F1 = 0.6981161613526066, consistency = 0.7730383211678832\n",
      "Batch 100 : F1 = 0.6985487785983577, consistency = 0.7732241843862088\n"
     ]
    }
   ],
   "source": [
    "consistencies = []\n",
    "f1scores = []\n",
    "\n",
    "fact_props = []\n",
    "\n",
    "for i in range(100):\n",
    "    lmbb.add_belief_set(fact_batches[i], constraint_solving=False, with_feedback=False)\n",
    "    fact_props += fact_batches[i]\n",
    "    c = lmbb.calculate_consistency()\n",
    "    f1 = lmbb.calculate_f1(fact_props)\n",
    "    print(f\"Batch {i+1} : F1 = {f1}, consistency = {c}\")\n",
    "    consistencies.append(c)\n",
    "    f1scores.append(f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbb.calculate_consistency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_facts = [fact for fact in facts if fact.boolean == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root: Is a starling a terrestrial organism? \n",
      " (A) yes (B) no\n",
      "DEBUG:root:[('yes', array(0.2710582, dtype=float32)), ('no', array(0.9625627, dtype=float32))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(starling,IsA,terrestrial organism, False, 0.962)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = random.randint(0, len(true_facts))\n",
    "print(idx)\n",
    "lmbb.query(true_facts[idx], with_feedback=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advnlpkernel",
   "language": "python",
   "name": "advnlpkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "22bb8309d38f1e65544d46771276df01ff94c6adf407f8023f86ac86fc1d49c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
