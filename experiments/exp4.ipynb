{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e12df6d-ba6b-4433-9b84-0e44a81b85ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import experiment_setup\n",
    "from belief.evaluation import load_facts\n",
    "from belief.nli import load_nli_model, load_nli_tokenizer, run_nli\n",
    "from belief.lmbb import Proposition, LMBB\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "from z3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8ec9fe-f824-4bc3-b220-dea06f957513",
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = load_facts('data/calibration_facts.json', num_batches=1)[0]\n",
    "\n",
    "with open('cache/wdik.json', 'r') as f:\n",
    "    wdik = json.load(f)\n",
    "\n",
    "with open('data/constraints_v2.json', 'r') as f:\n",
    "    constraint_data = json.load(f)\n",
    "    \n",
    "with open('cache/raw_outs_calib.json', 'r') as f:\n",
    "    raw_outs = json.load(f)['outs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "018502d8-b7ca-4b25-83d9-1dd0baf0a21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/kushal/miniconda3/envs/ID/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:446: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "evaluator = LMBB(\n",
    "    model=None, \n",
    "    tokenizer=None, \n",
    "    raw_constraints=constraint_data['links'],\n",
    ")\n",
    "nli_model = load_nli_model()\n",
    "nli_tokenizer = load_nli_tokenizer()\n",
    "raw_outs_dict = {}\n",
    "for out in raw_outs:\n",
    "    raw_outs_dict[out['prop']] = {'yes': out['yes'], 'no': out['no']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "108f7a1e-2c05-4967-982c-0c5cdf3f3884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1072/1072 [02:09<00:00,  8.28it/s]\n"
     ]
    }
   ],
   "source": [
    "z3mult = 1000\n",
    "wdik_weight = 1.5\n",
    "NUM_FACTS = 3\n",
    "new_beliefs = {}\n",
    "\n",
    "for prop in tqdm(facts):\n",
    "    sent = prop.sentence\n",
    "    raw_out = raw_outs_dict[sent]\n",
    "    subject = prop.subject\n",
    "    if NUM_FACTS > 0:\n",
    "        wdik_facts = random.sample(wdik[subject], NUM_FACTS)\n",
    "    else:\n",
    "        wdik_facts = wdik[subject]\n",
    "    \n",
    "    bools = {}\n",
    "    optim = Optimize()\n",
    "\n",
    "    bools[sent] = Bool(sent)\n",
    "    optim.add_soft(bools[sent], int(raw_out['yes'] * z3mult))\n",
    "    optim.add_soft(Not(bools[sent]), int(raw_out['no'] * z3mult))\n",
    "\n",
    "    assertion = prop.get_assertion()\n",
    "    \n",
    "    for wik in wdik_facts:\n",
    "        bools[wik] = Bool(wik)\n",
    "        optim.add_soft(bools[wik], wdik_weight * z3mult)\n",
    "\n",
    "        # wik -> fact\n",
    "        nli_out = run_nli(premise=wik, hypothesis=assertion, model=nli_model, tokenizer=nli_tokenizer)\n",
    "        if nli_out['entailment'] > 0.9:\n",
    "            optim.add_soft(Implies(bools[wik], bools[sent]), int(nli_out['entailment'] * z3mult))\n",
    "        if nli_out['contradiction'] > 0.9:\n",
    "            optim.add_soft(Not(Implies(bools[wik], bools[sent])), int(nli_out['contradiction'] * z3mult))\n",
    "\n",
    "        # fact -> wik\n",
    "        nli_out = run_nli(premise=assertion, hypothesis=wik, model=nli_model, tokenizer=nli_tokenizer)\n",
    "        if nli_out['entailment'] > 0.9:\n",
    "            optim.add_soft(Implies(bools[sent], bools[wik]), int(nli_out['entailment'] * z3mult))\n",
    "        if nli_out['contradiction'] > 0.9:\n",
    "            optim.add_soft(Not(Implies(bools[sent], bools[wik])), int(nli_out['contradiction'] * z3mult))\n",
    "\n",
    "    optim.check()\n",
    "    mod = optim.model()\n",
    "    \n",
    "    new_beliefs[sent] = Proposition.from_sent(sent, boolean=bool(mod.evaluate(bools[sent])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "624ab6ae-76be-42bf-91a9-414403b5dea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8716323246099944\n",
      "Consistency: 0.9731226918342224\n"
     ]
    }
   ],
   "source": [
    "evaluator.set_beliefs(new_beliefs)\n",
    "print(\"F1:\", evaluator.calculate_f1(facts))\n",
    "print(\"Consistency:\", evaluator.calculate_consistency())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad437faf-08fd-403b-8a2d-f0980ca7c6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1072/1072 [02:09<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8737864027475624\n",
      "Consistency: 0.978046778826426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1072/1072 [02:10<00:00,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8405315564582069\n",
      "Consistency: 0.9741485432909315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def exp_4(t):\n",
    "    new_beliefs = {}\n",
    "    evaluator = LMBB(\n",
    "    model=None, \n",
    "    tokenizer=None, \n",
    "    raw_constraints=constraint_data['links'],\n",
    "    )\n",
    "    for prop in tqdm(facts):\n",
    "        sent = prop.sentence\n",
    "        raw_out = raw_outs_dict[sent]\n",
    "        subject = prop.subject\n",
    "        if NUM_FACTS > 0:\n",
    "            wdik_facts = random.sample(wdik[subject], NUM_FACTS)\n",
    "        else:\n",
    "            wdik_facts = wdik[subject]\n",
    "\n",
    "        bools = {}\n",
    "        optim = Optimize()\n",
    "\n",
    "        bools[sent] = Bool(sent)\n",
    "        optim.add_soft(bools[sent], int(raw_out['yes'] * z3mult))\n",
    "        optim.add_soft(Not(bools[sent]), int(raw_out['no'] * z3mult))\n",
    "\n",
    "        assertion = prop.get_assertion()\n",
    "\n",
    "        for wik in wdik_facts:\n",
    "            bools[wik] = Bool(wik)\n",
    "            optim.add_soft(bools[wik], wdik_weight * z3mult)\n",
    "\n",
    "            # wik -> fact\n",
    "            nli_out = run_nli(premise=wik, hypothesis=assertion, model=nli_model, tokenizer=nli_tokenizer)\n",
    "            if nli_out['entailment'] > t:\n",
    "                optim.add_soft(Implies(bools[wik], bools[sent]), int(nli_out['entailment'] * z3mult))\n",
    "            if nli_out['contradiction'] > t:\n",
    "                optim.add_soft(Not(Implies(bools[wik], bools[sent])), int(nli_out['contradiction'] * z3mult))\n",
    "\n",
    "            # fact -> wik\n",
    "            nli_out = run_nli(premise=assertion, hypothesis=wik, model=nli_model, tokenizer=nli_tokenizer)\n",
    "            if nli_out['entailment'] > t:\n",
    "                optim.add_soft(Implies(bools[sent], bools[wik]), int(nli_out['entailment'] * z3mult))\n",
    "            if nli_out['contradiction'] > t:\n",
    "                optim.add_soft(Not(Implies(bools[sent], bools[wik])), int(nli_out['contradiction'] * z3mult))\n",
    "\n",
    "        optim.check()\n",
    "        mod = optim.model()\n",
    "\n",
    "        new_beliefs[sent] = Proposition.from_sent(sent, boolean=bool(mod.evaluate(bools[sent])))\n",
    "    evaluator.set_beliefs(new_beliefs)\n",
    "    print(\"F1:\", evaluator.calculate_f1(facts))\n",
    "    print(\"Consistency:\", evaluator.calculate_consistency())\n",
    "\n",
    "exp_4(0.8)\n",
    "exp_4(0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f29eb81e-b694-44a3-9502-d3a7742a741f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1072/1072 [02:10<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8662420331922188\n",
      "Consistency: 0.9772260976610587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1072/1072 [02:09<00:00,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8607594886454495\n",
      "Consistency: 0.973533032416906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exp_4(0.92)\n",
    "exp_4(0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10dee61a-8a36-45fc-b1b4-3ca81151e79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1072/1072 [02:09<00:00,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8720238045065369\n",
      "Consistency: 0.973533032416906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exp_4(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f80386-0a42-4eaf-aae7-371e81369ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
