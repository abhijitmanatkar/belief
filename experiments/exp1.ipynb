{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f71d3d-c2f0-4cc8-b7ce-21967ce53208",
   "metadata": {},
   "source": [
    "## Experiment 1: Using WDIK information as additional context while answering questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "133a6694-bdcd-4806-a946-fdbe6eb28ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a9006e-c483-4a31-8194-a4c181853ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from belief.utils import load_macaw, load_tokenizer\n",
    "from belief.utils import macaw_input, run_macaw, get_macaw_scores, get_macaw_outs\n",
    "from belief.evaluation import load_facts\n",
    "from belief.lmbb import LMBB\n",
    "import json\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "684cb8f3-2582-4eb6-9301-42e385a31a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = load_facts('data/calibration_facts.json', num_batches=1)[0]\n",
    "\n",
    "with open('cache/wdik.json', 'r') as f:\n",
    "    wdik = json.load(f)\n",
    "    \n",
    "with open('data/constraints_v2.json', 'r') as f:\n",
    "    constraint_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ebedd2fc-067e-4fc1-87c4-1abddc5900a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FACTS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dc764fde-8eb6-444c-933d-63fa03fd8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = LMBB(\n",
    "    model=None, \n",
    "    tokenizer=None, \n",
    "    raw_constraints=constraint_data['links'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c1da3ef1-4ad2-4e29-bf84-fb84f8803839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    }
   ],
   "source": [
    "model = load_macaw()\n",
    "tokenizer = load_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "715672c2-5463-4ca6-9789-f5b5e6d8258f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1072/1072 [36:27<00:00,  2.04s/it]\n"
     ]
    }
   ],
   "source": [
    "answer_beliefs = {}\n",
    "\n",
    "yes_no = ['yes', 'no']\n",
    "\n",
    "for fact in tqdm(facts):\n",
    "    entity = fact.subject\n",
    "    context = ' '.join(random.sample(wdik[entity], NUM_FACTS))\n",
    "    question = fact.get_question()\n",
    "    inp_str = macaw_input(question=question, options=yes_no, context=context, targets='A')\n",
    "    outs = get_macaw_outs(inp_str, model, tokenizer)\n",
    "    ans_fact = copy.deepcopy(fact)\n",
    "    if 'yes' in outs['answer']:\n",
    "        ans_fact.boolean = True\n",
    "    elif 'no' in outs['answer']:\n",
    "        ans_fact.boolean = False\n",
    "    else:\n",
    "        print(f\"Random assignment: {fact.sentence}\")\n",
    "        ans_fact.boolean = random.choice([True, False])\n",
    "    answer_beliefs[ans_fact.sentence] = ans_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a0b8ed43-4890-48f7-b09a-85d95e35c482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.83307809604741\n",
      "Consistency: 0.9675830939679935\n"
     ]
    }
   ],
   "source": [
    "evaluator.set_beliefs(answer_beliefs)\n",
    "print(\"F1:\", evaluator.calculate_f1(facts))\n",
    "print(\"Consistency:\", evaluator.calculate_consistency())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advnlpkernel",
   "language": "python",
   "name": "advnlpkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
